# ğŸš€ QUICK START GUIDE

## Step-by-Step Setup & Running

### âœ… Step 1: Install Dependencies
```bash
pip install -r Requirements.txt
```

### âœ… Step 2: Start Ollama (in a separate terminal)
```bash
ollama serve
```

### âœ… Step 3: Ingest Data (First Time Only)
```bash
cd 2_scripts
python 1_ingest_data.py
```

This will:
- Read the Excel file from `4_data/`
- Extract and preprocess the data
- Create embeddings
- Store in `4_data/data_prototype/`

**Expected output:**
```
âœ… Created 153 documents
ğŸ”‹ TOTAL PLANT CONSUMPTION: 18,221,587.14 KWH
âœ… COMPLETE! Documents in store: 153
```

### âœ… Step 4: Run Streamlit UI
```bash
cd ../3_ui
streamlit run 2_run_streamlit_ui.py
```

**Or from root directory:**
```bash
streamlit run 3_ui/2_run_streamlit_ui.py
```

### âœ… Step 5: Open Browser
Go to: **http://localhost:8501**

---

## ğŸ“ Folder Structure

```
langchain-agentic-dashboard/
â”‚
â”œâ”€â”€ 1_core/                          # Core backend files (don't run directly)
â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”œâ”€â”€ smart_preprocessor.py        # Data extraction logic
â”‚   â”œâ”€â”€ embedding_store.py           # Vector search
â”‚   â”œâ”€â”€ llm_reasoning.py            # LLM query answering
â”‚   â”œâ”€â”€ router.py                   # Query routing
â”‚   â”œâ”€â”€ agent_tools.py              # Calculations
â”‚   â”œâ”€â”€ utils.py                    # Utilities
â”‚   â”œâ”€â”€ user_profiles.py            # User management
â”‚   â””â”€â”€ ingestion_pipeline.py       # Legacy file processing
â”‚
â”œâ”€â”€ 2_scripts/                       # Scripts to run (in order)
â”‚   â””â”€â”€ 1_ingest_data.py            # âš¡ RUN THIS FIRST (one time)
â”‚
â”œâ”€â”€ 3_ui/                           # User interface
â”‚   â””â”€â”€ 2_run_streamlit_ui.py       # âš¡ RUN THIS TO START UI
â”‚
â”œâ”€â”€ 4_data/                         # Data files
â”‚   â”œâ”€â”€ Energy Consumption Daily Report MHS Ele - Copy.xlsx
â”‚   â””â”€â”€ data_prototype/             # Generated databases & indexes
â”‚
â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ PRODUCTION_HANDOVER.md      # For web developers
â”‚   â””â”€â”€ README.md                   # Project overview
â”‚
â””â”€â”€ Requirements.txt                # Python dependencies
```

---

## ğŸ¯ What Each Script Does

### 1ï¸âƒ£ `2_scripts/1_ingest_data.py`
**Purpose:** Load and process Excel data into the system
**When to run:** 
- First time setup
- When you have a new Excel file to add
**Time:** ~5 seconds

### 2ï¸âƒ£ `3_ui/2_run_streamlit_ui.py`
**Purpose:** Start the web interface for testing
**When to run:** Every time you want to use the chatbot
**Time:** Runs continuously until you stop it (Ctrl+C)

---

## ğŸ”§ Troubleshooting

**Error: "Module not found"**
â†’ Run: `pip install -r Requirements.txt`

**Error: "LLM Error" or timeout**
â†’ Check Ollama is running: `ollama serve`
â†’ Check models are installed: `ollama list`
â†’ Install if needed: `ollama pull llama3.2` and `ollama pull nomic-embed-text`

**Error: "No data found"**
â†’ Run: `python 2_scripts/1_ingest_data.py`

**Port already in use (8501)**
â†’ Streamlit will automatically try 8502, 8503, etc.
â†’ Or stop the existing one: `pkill -f streamlit`

---

## ğŸ“¦ For Web Developers

See `docs/PRODUCTION_HANDOVER.md` for integration guide with REST API examples.
